# Использование методов машинного обучения для анализа переменных звёзд

## Описание проекта

Данный репозиторий объединяет два этапа исследования:

1. **Бинарная классификация**: построение модели, отличающей переменные звёзды от статичных объектов.
2. **Мультиклассовая классификация**: расширение задачи на выделение типов переменных звёзд (затменные, пульсирующие, ротационные, эруптивные).

Цель — надёжное выявление переменных звёзд и классификация наиболее распространённых типов при сильном дисбалансе классов.

---

## Часть 1. Бинарная классификация

### Подготовка данных

1. Загрузка `whole_data_practice3.csv`.
2. Удаление столбца `type` (>90% пропусков).
3. Отбрасывание первых 5 строк (возможные некоррекции).
4. Анализ корреляций, удаление сильно скоррелированных признаков: `Bmag`, `gpmag`, `rpmag`, `ipmag`.
5. Визуализация распределений (гистограммы, boxplot, violin).
6. Понижение размерности t‑SNE для визуализации классов.
7. Масштабирование RobustScaler (устойчивость к выбросам).

### Обучение и оптимизация

* Алгоритмы: LogisticRegression, KNN, DecisionTree, RandomForest, GradientBoosting.
* Балансировка: SMOTE + Pipeline.
* Подбор гиперпараметров через GridSearchCV (max\_depth=12, k\_neighbors=5).

**Итоговые метрики финального GBM:**

| Метрика   | Значение |
| --------- | -------- |
| Accuracy  | 0.92     |
| Precision | 0.59     |
| Recall    | 0.77     |
| F1-score  | 0.67     |

### Стэкинг (StackingClassifier)

Использованы базовые модели: CatBoost, XGBoost, LightGBM. Финальный классификатор — LogisticRegression. Порог принятия решения выбран по precision–recall кривой.

**Финальные метрики стэкинга:**

| Метрика   | Значение |
| --------- | -------- |
| Accuracy  | 0.94     |
| Precision | 0.65     |
| Recall    | 0.85     |
| F1-score  | 0.74     |

**Матрица ошибок:**

|           | Predicted: 0 | Predicted: 1 |
| --------- | ------------ | ------------ |
| Actual: 0 | 11081        | 599          |
| Actual: 1 | 203          | 1114         |

---

## Часть 2. Мультиклассовая классификация

### Данные и цель

* Источник данных: [VSX-паркет](https://drive.google.com/file/d/1wTkOoA222guACzvIJxLf4wU77Rykp1__/view?usp=sharing)
* Задача: классифицировать объекты на четыре класса:

  1. **ECLIPSING** (затменные) - 2 568 649 объектов
  2. **PULSATING** (пульсирующие) - 3 089 412
  3. **ROTATING** (ротационные) - 3 102 285
  4. **ERUPTIVE** (эруптивные) - 97 179, редкий класс

### Предобработка и feature engineering

```python
df = pd.read_parquet("./data/B_vsx_vsx.parquet")
# Функция classify_type() группирует Type → класс
# Отбрасываем UNKNOWN, удаляем лишние столбцы, обрабатываем Period
# Создаём признак has_period: 1 если есть период, иначе 0
# Достаём новый признак из Name
# Обработка редких значений и применение LabelEncoder для категорий: Name, Sp, n_max, n_min
# Новый признак amplitude = min - max
# Масштабируем: max, min, Period, RAJ2000, DEJ2000, range
```

### Обучение моделей на подмножестве (300 000 объектов)

1. **LogisticRegression** (`class_weight='balanced'`)

   * ERUPTIVE: precision = 0.05, recall = 0.67, f1 = 0.09

2. **CatBoostClassifier** (`auto_class_weights='Balanced'`, `eval_metric='TotalF1'`)

   * ERUPTIVE: precision = 0.79, recall = 0.23, f1 = 0.36
   * Общая accuracy = 0.91, macro\_avg f1 ≈ 0.78

### Улучшение детекции редкого класса ERUPTIVE

* Обучен отдельный CatBoost-детектор с помощью Optuna (50 испытаний)
* Подбор порога вероятности `proba_eruptive > 0.95` — присвоение класса ERUPTIVE
* Комбинирование предсказаний основной модели и детектора

### Финальная модель на полном наборе

**Результаты по классам:**

| Метрика   | ECLIPSING | ERUPTIVE | PULSATING | ROTATING |
| --------- | --------- | -------- | --------- | -------- |
| Precision | 0.97      | 0.65     | 0.92      | 0.93     |
| Recall    | 0.93      | 0.67     | 0.94      | 0.94     |
| F1-score  | 0.95      | 0.66     | 0.93      | 0.94     |

**Общие метрики:**
Accuracy = 0.94
Macro avg F1 = 0.87
Weighted avg F1 = 0.94

**Матрица ошибок:**

| Actual \ Predicted | 0 (ECLIPSING) | 1 (ERUPTIVE) | 2 (PULSATING) | 3 (ROTATING) |
| ------------------ | ------------- | ------------ | ------------- | ------------ |
| 0 (ECLIPSING)      | 494496        | 312          | 21645         | 16430        |
| 1 (ERUPTIVE)       | 1107          | 12481        | 2369          | 2798         |
| 2 (PULSATING)      | 8009          | 3357         | 570889        | 23243        |
| 3 (ROTATING)       | 8705          | 2920         | 22370         | 577544       |

---

## Запуск кода

1. Установить зависимости:

   ```bash
   pip install pandas numpy scikit-learn imbalanced-learn catboost xgboost lightgbm optuna
   ```

2. Открыть ноутбук с бинарной классификацией:

   [research.ipynb (nbviewer)](https://nbviewer.org/github/StalSkyle/stars_classification/blob/main/research.ipynb?flush_cache=true)

3. Открыть ноутбук с мультиклассовой классификацией:

   [multi\_classification.ipynb (nbviewer)](https://nbviewer.org/github/StalSkyle/stars_classification/blob/main/multi_classification.ipynb?flush_cache=true)

---

## Выводы

Использование методов балансировки классов (SMOTE), подбор гиперпараметров и стэкинг моделей на основе бустинга позволили достичь высокой полноты и хорошего F1. Итоговая модель эффективно справляется с задачей выявления переменных звёзд даже в условиях значительного дисбаланса классов.

Для мультиклассовой классификации применение CatBoost с автоматическим взвешиванием классов, специализированного детектора редкого класса ERUPTIVE и комбинированного порогового подхода позволило достичь macro\_avg F1 ≈ 0.87 и стабильных метрик по всем классам.
