# Использование методов машинного обучения для анализа переменных звёзд

## Описание проекта

Данный репозиторий объединяет два этапа исследования:

1. **Бинарная классификация**: построение модели, отличающей переменные звёзды от статичных объектов.
2. **Мультиклассовая классификация**: расширение задачи на выделение типов переменных звёзд (затменные, пульсирующие, ротационные, эруптивные).

Ключевая цель — надёжное выявление переменных звёзд и классификация наиболее распространённых типов при сильном дисбалансе классов.

---

## Часть 1. Бинарная классификация

### Подготовка данных

1. Загрузка `whole_data_practice3.csv`.
2. Удаление столбца `type` (>90% пропусков).
3. Отбрасывание первых 5 строк (возможные некоррекции).
4. Анализ корреляций, удаление сильно скоррелированных признаков: `Bmag`, `gpmag`, `rpmag`, `ipmag`.
5. Визуализация распределений (гистограммы, boxplot, violin).
6. Понижение размерности t‑SNE для визуализации классов.
7. Масштабирование RobustScaler (устойчивость к выбросам).

### Обучение и оптимизация

* Алгоритмы: LogisticRegression, KNN, DecisionTree, RandomForest, GradientBoosting.
* Балансировка: SMOTE + Pipeline.
* Подбор гиперпараметров через GridSearchCV (max\_depth=12, k\_neighbors=5).

**Итоговые метрики финального GBM:**

| Метрика   | Значение |
| --------- | -------- |
| Accuracy  | 0.92     |
| Precision | 0.59     |
| Recall    | 0.77     |
| F1-score  | 0.67     |

### Стэкинг (StackingClassifier)

Использованы базовые модели: CatBoost, XGBoost, LightGBM. Финальный классификатор — LogisticRegression. Порог принятия решения выбран по precision–recall кривой.

**Финальные метрики стэкинга:**

| Метрика   | Значение |
| --------- | -------- |
| Accuracy  | 0.94     |
| Precision | 0.65     |
| Recall    | 0.85     |
| F1-score  | 0.74     |

---

## Часть 2. Мультиклассовая классификация

### Данные и цель

* Источник данных: [VSX-паркет](https://drive.google.com/file/d/1wTkOoA222guACzvIJxLf4wU77Rykp1__/view?usp=sharing).
* Задача: классифицировать объекты на четыре класса:

  1. **ECLIPSING** (затменные)
  2. **PULSATING** (пульсирующие)
  3. **ROTATING** (ротационные)
  4. **ERUPTIVE** (эруптивные)

### Предобработка и feature engineering

```python
df = pd.read_parquet("./data/B_vsx_vsx.parquet")
# Функция classify_type() группирует Type → класс
# Отбрасываем UNKNOWN, удаляем лишние столбцы, обрабатываем Period
# Создаём признак has_period: 1 если есть период, иначе 0
# Достаём новый признак из Name
# Обработка редких значений и применение LabelEncoder для категорий: Name, Sp, n_max, n_min
# Новый признак amplitude = min - max
# Масштабируем: max, min, Period, RAJ2000, DEJ2000, range
```

* Удалены нерелевантные и плохо заполненные признаки.
* Кодирование меток и бинарных флагов (f\_min, has\_period).

### Обучение моделей на подмножестве (300 000 объектов)

1. **LogisticRegression** (class\_weight='balanced').

   ```python
   # Результат:
   # ERUPTIVE: precision=0.05, recall=0.67, f1=0.09
   ```
2. **CatBoostClassifier** (auto\_class\_weights='Balanced', eval\_metric='TotalF1'):

   ```python
   # ERUPTIVE: precision=0.79, recall=0.23, f1=0.36
   # Общая accuracy=0.91, macro_avg f1≈0.78
   ```

### Улучшение детекции редкого класса ERUPTIVE

* Обучен отдельный CatBoost детектор (binary) с помощью Optuna (50 испытаний).
* Подобран threshold на proba\_eruptive (>0.7 - меняем предсказание основной модели на ERUPTIVE, <0.4 - основная модель предсказывает другой класс) для переназначения класса.
* Комбинирование предсказаний основного CatBoost и детектора.

```python
# На подмножестве:
# ERUPTIVE: precision=0.55, recall=0.58, f1=0.57
# macro_avg f1≈0.84, accuracy≈0.93
```

### Финальная модель на полном наборе

```python
# CatBoost (Balanced) + детектор eruptive с threshold 0.95 и изменением класса, если модель уверена с вероятностью меньше, чем 0.8
# Результаты на тесте:
# ECLIPSING: precision=0.97, recall=0.93, f1=0.95
# ERUPTIVE: precision=0.65, recall=0.67, f1=0.66
# PULSATING: precision=0.92, recall=0.94, f1=0.93
# ROTATING: precision=0.93, recall=0.94, f1=0.94
# accuracy=0.94, macro_avg f1≈0.87
```

---

## Запуск кода

1. Установить зависимости:

   ```bash
   pip install pandas numpy scikit-learn imbalanced-learn catboost xgboost lightgbm optuna
   ```
2. Открыть ноутбук с бинарной классификацией:

   ```bash
   https://nbviewer.org/github/StalSkyle/stars_classification/blob/main/research.ipynb?flush_cache=true
   ```
3. Открыть ноутбук с мультиклассовой классификацией:

   ```bash
   https://nbviewer.org/github/StalSkyle/stars_classification/blob/main/multi_classification.ipynb?flush_cache=true
   ```

---

## Выводы

Использование методов балансировки классов (SMOTE), подбор гиперпараметров и стэкинг моделей на основе бустинга позволили достичь высокой полноты и хорошего F1. Итоговая модель эффективно справляется с задачей выявления переменных звёзд даже в условиях значительного дисбаланса классов.

Для мультиклассовой классификации применение CatBoost с автоматическим взвешиванием классов, специализированного детектора редкого класса ERUPTIVE и комбинированного порогового подхода позволило достичь macro_avg F1≈0.87 и стабильных метрик по всем классам.
